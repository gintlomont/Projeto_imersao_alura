{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "O0sFK5BaVSE2"
      ],
      "mount_file_id": "1qjc3PaPBgaCIRZdPwrFGKmFVST-xUxG0",
      "authorship_tag": "ABX9TyNDbo30mm9r4MBxEclP2h9S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gintlomont/Projeto_imersao_alura/blob/main/projeto_Sistema_de_An%C3%A1lise_de_Dados_e_Conversa%C3%A7%C3%A3o_da_imersao_alura.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sistema de An√°lise de Dados e Conversa√ß√£o com Chat Utilizando Google Generative AI\n",
        "\n",
        "\n",
        "*   Este c√≥digo cria um sistema no console que oferece an√°lise de dados e chatbot. Com a API do Google Generative AI, os usu√°rios podem carregar arquivos CSV, JSON ou TXT para an√°lise, fornecendo prompts para orientar a an√°lise.\n",
        "*   Al√©m disso, podem conversar com um chatbot alimentado pela tecnologia de gera√ß√£o de linguagem natural do Google. Ideal para extrair insights de dados ou interagir com um chatbot avan√ßado no console Python.\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "Exemplos: <br>\n",
        "Voce pode usar o seu arquivo ou link da irmars√£o (arquivo json)\n",
        "\n",
        "1.   https://raw.githubusercontent.com/guilhermeonrails/api-imersao-ia/main/words.json\n",
        "2.   Do que se trata este arquivo.\n",
        "3.   Descreve este arquivo.\n",
        "2.   Quais s√£o os principais insights que podem ser extra√≠dos deste dados.\n",
        "4.   Pergunte o que quiser sobre os seus arquivo ou dados\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WxPu_1Z_Ui8Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.   Importar biblitecas\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "O0sFK5BaVSE2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gsAiBkS3S9sy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "\n",
        "# bibliteca que trabalha com formata√ß√£o do texto\n",
        "import textwrap\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# bibliteca que limpa tela\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# bibloteca time\n",
        "from time import sleep"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Configurar a API do Google Generative AI"
      ],
      "metadata": {
        "id": "xbd_gz6YWY0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY = 'Coloque o se API_kEY'\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# configurar Genai\n",
        "generation_config = {\n",
        "  \"candidate_count\": 1,\n",
        "  \"temperature\": 1,\n",
        "}\n",
        "\n",
        "safety_settings={\n",
        "    'HATE': 'BLOCK_NONE',\n",
        "    'HARASSMENT': 'BLOCK_NONE',\n",
        "    'SEXUAL' : 'BLOCK_NONE',\n",
        "    'DANGEROUS' : 'BLOCK_NONE'\n",
        "    }\n",
        "model = genai.GenerativeModel('gemini-pro', safety_settings, generation_config, )"
      ],
      "metadata": {
        "id": "SzMut0RsWf6j"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Criando Fun√ßoes importantes"
      ],
      "metadata": {
        "id": "MPiDbGvAXLde"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Analisador de dados"
      ],
      "metadata": {
        "id": "f5DjUKPEXWWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analisar_dados(dados, prompt=None):\n",
        "    \"\"\"Analisa os dados fornecidos usando o Gemini-pro e retorna os insights.\"\"\"\n",
        "\n",
        "    # Limitando a quantidade de linhas exibidas para evitar ultrapassar o numeros de tokens permitidos\n",
        "    #dados = dados[150].to_string()\n",
        "\n",
        "    # Preparar a entrada para o Gemini-pro\n",
        "    texto_entrada = f\"Dados: {dados}\\nPrompt: {prompt}\"\n",
        "\n",
        "    # Gerar insights com o Gemini-pro\n",
        "    resposta = chat.send_message(texto_entrada)\n",
        "    insights = resposta.text\n",
        "\n",
        "    # Retornar os insights\n",
        "    return insights"
      ],
      "metadata": {
        "id": "XXL2fDOYXtEK"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Detector de formato de dados"
      ],
      "metadata": {
        "id": "-16j4rhpX8EK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tem_formato(dados):\n",
        "  format = dados.split('.')\n",
        "  return format[-1]\n"
      ],
      "metadata": {
        "id": "2hLsjw6MYDWE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Tela de menu inicial, de exibi√ß√£o, titulo e de caregamento de dados"
      ],
      "metadata": {
        "id": "a0Pn8SX7biVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def menu_principal():\n",
        "    \"\"\"Exibe o menu principal e retorna a escolha do usu√°rio.\"\"\"\n",
        "    titulo(\"Sistema de An√°lise de Dados e Conversa√ß√£o\")\n",
        "    print(\"  Selecione uma op√ß√£o:\")\n",
        "    print(\"  1. Analisar os dados\")\n",
        "    print(\"  2. Conversar com o chat\")\n",
        "    print(\"  3. consultar o historico\\n\")\n",
        "    opcao = input(\"  Escolha uma op√ß√£o (1 ou 2, 999 para sair.): \")\n",
        "    return opcao\n",
        "\n",
        "\n",
        "# fun√ß√£o mostrar linhas de cabe√ßalho e centralizar o cabe√ßalho\n",
        "def titulo(msg):\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"{msg:^50}\")\n",
        "    print(\"-\" * 50, \"\\n\")\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "    text = text.replace('‚Ä¢', '  *')\n",
        "    return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "\n",
        "# Fun√ß√£o para carregar dados e extrair formato\n",
        "def carregar_dados():\n",
        "    caminho = input(\"Digite o caminho do arquivo: \")\n",
        "    formato_dados = tem_formato(caminho)  # verificar o formato de arquivo\n",
        "\n",
        "    # 1. Carregar e pr√©-processar os dados\n",
        "    if isinstance(formato_dados, str) and formato_dados in [\"csv\", \"json\", \"txt\"]:\n",
        "        try:\n",
        "            if formato_dados == \"csv\":\n",
        "                dados = pd.read_csv(caminho)\n",
        "            elif formato_dados == \"json\":\n",
        "                dados = pd.read_json(caminho)\n",
        "            elif formato_dados == \"txt\":\n",
        "                dados = pd.read_csv(caminho, delimiter='\\t')\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            return False, None\n",
        "    else:\n",
        "        # caso formato n√£o seja [\"csv\", \"json\", \"txt\"]\n",
        "        return False, None\n",
        "    return True, dados\n"
      ],
      "metadata": {
        "id": "eIf3LoI2bpnt"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 Conversar com Chat"
      ],
      "metadata": {
        "id": "ZueRLCR6b8d0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fun√ß√£o para conversar com o chat\n",
        "def conversar_chat():\n",
        "\n",
        "    # limpar tela ou console\n",
        "    clear_output()\n",
        "\n",
        "    # mostrar titulo\n",
        "    titulo(\"Chat de conversa√ß√£o\")\n",
        "\n",
        "    while True:\n",
        "\n",
        "        # receber chat de usuario\n",
        "        print(\"\\033[1;33mUser -> \\033[0m\")\n",
        "        prompt = input(\"Fa√ßa sua pergunta: \")\n",
        "        print()\n",
        "\n",
        "        # verificar a saida\n",
        "        if prompt == \"999\":\n",
        "            break\n",
        "\n",
        "        # fazer requisi√ß√£o e imprimir\n",
        "        resposta = chat.send_message(prompt)\n",
        "        print(\"\\033[1;32mResposta do chat:\\033[0m\")\n",
        "        display(to_markdown(f'\\n\\n{resposta.text}'))\n",
        "\n",
        "        print(\"\\n-----------------------------------------------------------\\n\")"
      ],
      "metadata": {
        "id": "3E4WHnuQcGm1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5 Consultar o historico da conversa"
      ],
      "metadata": {
        "id": "a08hLqULCZE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ver_historico():\n",
        "\n",
        "    # mostrar titulo\n",
        "    titulo(\"Historico de conversa\")\n",
        "\n",
        "    # Verificar se h√° conte√∫do no hist√≥rico\n",
        "    if chat.history:\n",
        "        # Imprimir o hist√≥rico\n",
        "        for message in chat.history:\n",
        "            display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))\n",
        "            print('-------------------------------------------')\n",
        "    else:\n",
        "        print(\"O hist√≥rico est√° vazio.\")"
      ],
      "metadata": {
        "id": "6XNQFxE-C6fS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5 Programa principal"
      ],
      "metadata": {
        "id": "OWh2bMdscM-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop principal\n",
        "\n",
        "# fazendo requisi√ß√£o ao gemini no modo gerar historico\n",
        "chat = model.start_chat(history=[])\n",
        "while True:\n",
        "\n",
        "    # limpar tela ou console\n",
        "    clear_output()\n",
        "\n",
        "    opcao = menu_principal()\n",
        "\n",
        "    if opcao == '1':\n",
        "\n",
        "        # limpar tela ou console\n",
        "        clear_output()\n",
        "\n",
        "        # mostrar titulo\n",
        "        titulo(\"Sistema de An√°lise de Dados\")\n",
        "        foi_carregado, dados = carregar_dados()\n",
        "\n",
        "        if foi_carregado is True:\n",
        "\n",
        "            while True:\n",
        "\n",
        "                print(\"\\n\\033[1;33mUser -> \\033[0m\")\n",
        "                prompt = input(\"Digite uma pergunta sobre os dados: \")\n",
        "\n",
        "                # verificar a saida\n",
        "                if prompt == \"999\":\n",
        "                    break\n",
        "\n",
        "                # chamada de fun√ß√£o responsavel por analisar dados\n",
        "                insights = analisar_dados(dados, prompt)\n",
        "\n",
        "                # imprimir o resultado\n",
        "                print()\n",
        "                print(\"\\033[1;32mResposta do chat:\\033[0m\")\n",
        "                display(to_markdown(f'\\n\\n{insights}'))\n",
        "\n",
        "                print(\"\\n-----------------------------------------------------------\\n\")\n",
        "\n",
        "        else:\n",
        "            #print(\"\\n\\033[1;31mERRO!\\033[m\")\n",
        "            print(\"\\n\\033[1;31mERRO!\\033[0m\")\n",
        "            print('Verifique se a exten√£o termina em (\"csv\", \"json\", \"txt\") ou se cominho esta correto...')\n",
        "            sleep(5)\n",
        "\n",
        "    elif opcao == '2':\n",
        "        # limpar tela ou console\n",
        "        clear_output()\n",
        "        resp = conversar_chat()\n",
        "\n",
        "    elif opcao == \"3\":\n",
        "        # limpar tela ou console\n",
        "        clear_output()\n",
        "        ver_historico()\n",
        "\n",
        "        # este comando so impede limpar tela ante que o usuario termina de ler historico\n",
        "        input(\"Digite qualquer letra para sair: \")\n",
        "\n",
        "    elif opcao == \"999\":\n",
        "        print(\"\\nSaindo...\")\n",
        "        sleep(1)\n",
        "        print(\"Obrigado por usar o nosso sistema. Volte sempre e at√© logo üëãüòä.\")\n",
        "        break\n",
        "\n",
        "    else:\n",
        "        print(\"  \\033[1;31mOp√ß√£o inv√°lida. Por favor, escolha 1, 2 ou 3.\\033[0m\")\n",
        "        sleep(2)\n",
        ""
      ],
      "metadata": {
        "id": "tKWDv29mcTIA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}